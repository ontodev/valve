#+title:Converting VALVE functions into SQL

* Notes:
  - In the analyses below it is assumed that we have actually been able to
    parse the arguments to a given function. This is non-trivial, but the same
    method can probably be used to do this for all functions. We will bracket
    this for now.

  - (from James): To handle the nested conditions, I expect the general
    strategy will be to use multiple Common Table Expressions (CTEs): WITH
    first AS (...), second AS (...), third AS (...) SELECT ... . I've never
    done that, but it should work: https://www.sqlite.org/lang_with.html

* any
This seems to be reasonably straightforward and can be implemented, it seems,
with a simple ~OR~.

It will get more complicated when the expressions referred to are themselves
functions, but that complication has nothing to do with ~any~ per se, but with
the general issue of how to compose functions in these SQL queries. James'
suggestion (see the *Notes* section above) should work.

The other complication, which is also general and applies to all functions, is
when an expression is a datatype that has a parent. In that case we will need
to generate queries for the original datatype and also for its ancestors.

* concat

Consider:

#+begin_example
 table    | column | condition
--------------------------------------------------------------------------------------
 external | ID     | concat(label, " ; ", in(table.column), " & ", under(table.column))
#+end_example

And suppose that the ~`external`~ table looks like:

#+begin_example
 ID
-----------------
 foo ; bar & baz
 goo ; jar & jazz
#+end_example

The function will then need to split up the ~`ID`~ column using the pattern
passed to the ~concat~ function. In this case it says that the contents of
~`external`.`ID`~ should conform to:

- an expression which must correspond to a label, followed by:
- a semicolon surrounded by spaces, followed by:
- an expression which must be ~in~ the column: ~`table`.`column`~, followed by:
- an ampersand surrounded by spaces, followed by:
- an expression which must be ~under~ the column: ~`table`.`column`~.

Here is another, slightly simpler, example:

#+begin_example
 table    | column | condition
-----------------------------------------------------------------------------------------------------------------------------
 sports   | prefs  | concat("My three favourite NFL teams: 1. ", in(nfl.teams), ", 2. " in(nfl.teams), ", 3. ", in(nfl.teams)
#+end_example

where the ~nfl~ table has the following contents:
#+begin_example
 teams
------------
 Bears
 Lions
 Packers
 Bills
 Patriots
 Seahawks
 49ers
 ...
#+end_example

Rows in the ~`sports`~ table will look like:

#+begin_example
 fan    | prefs
-----------------------------------------------------------------------
 Mike   | My three favourite NFL teams: 1. Packers, 2. Bills, 3. Seahawks
 Jenny  | My three favourite NFL teams: 1. Bears, 2. Leafs, 3. Patriots
#+end_example

Note that in the second row, 'Leafs' is not ~in(nfl.teams)~ (since the Leafs
are a hockey team), so this should show up as invalid.

One thing we might be able to do is to take the arguments to ~concat~ and use
them to create a regular expression. That regular expression could then be
matched against the target column. So in the first example we'd want to
validate that the contents of ~ID~ look like:

~^\w+ ; \w+ & \w+$~

and in the second case we'd want to validate that the contents of ~prefs~ look
like:

 ~^My three favourite NFL teams: 1. \w+, 2. \w+, 3. \w+$~.

It would be nice if the regex function we implement could support capturing,
e.g.,

 ~^My three favourite NFL teams: 1. (\w+), 2. (\w+), 3. (\w+)$~.

Unfortunately, although we can of course implement capturing in the underlying
Java code for our user-defined function, the [[https://www.javadoc.io/doc/org.xerial/sqlite-jdbc/3.36.0/org/sqlite/Function.html][API for user defined functions]]
doesn't seem to allow us to actually return them *directly*; i.e., the various
~result()~ functions only support returning byte arrays, numbers, and
strings. Apparently SQLite also supports so-called [[https://www.sqlite.org/vtab.html][table-valued functions]], but
that is a whole other kettle of fish, and it's not clear that we can use these
in the same way that we use user-defined functions.

There is a workaround, though. It is slightly clunkier but it should work. The
idea is to have the ~regexp_capture()~ (or whatever we call it) send back the
list of captures as a *delimited string*, i.e.,

#+begin_src java
protected void xFunc() throws SQLException {
  // A bunch of code can go here to do the capturing by calling Java's
  // java.util.regex library
  // ...
  // Then we return what we have captured:
  String retString = new String();
  for (String capture : captures) {
    retString += catpure;
    retString += "@";
  }
  result(retString);
}
#+end_src

~@~ is probably not the best choice of delimiter, but we can likely find
something suitable, e.g., a non-printable character. So to sum up (assuming
that we have parsed the arguments to concat, we then):

1. Generate a match string, which in our example would be: "My three favourite
   NFL teams: 1. (\w+), 2. (\w+), 3. (\w+)"

2. Call ~regexp_capture()~ on the contents of the ~`sports`.`prefs`~ table,
   using the match string generated as the second argument. Something like:

#+begin_src sql
select regexp_capture(prefs, "My three favourite NFL teams: 1. (\w+), 2. (\w+), 3. (\w+)")
from sports;
#+end_src

If the capture has been successful, we will get back a string that looks
something like:

"capture1@capture2@capture3"

3. We can then split this string and validate each capture in accordance with
   its corresponding argument, which in this case would be ~in(nfl.teams)~
   for all three.

Here is some code to do this:
#+begin_src sql
with captures(fan, capture) as (
  with recursive captures(fan, capture, str) as (
    select
      fan,
      '',
      regexp_capture(prefs, "My three favourite NFL teams: 1. (\w+), 2. (\w+), 3. (\w+)")
    from sports
    union all
    select
      fan,
      substr(str, 0, instr(str, '@')),
      substr(str, instr(str, '@')+1)
    from captures where str != ''
  )
  select fan, capture
  from captures
  where capture != ''
)
select
  fan,
  capture,
  capture in (select teams from nfl) as valid_pref
from captures
order by fan;
#+end_src

The result will look like:
#+begin_example
 fan   | capture  | valid
-------------------------
 Jenny | Bears    | 1
 Jenny | Leafs    | 0
 Jenny | Patriots | 1
 Mike  | Packers  | 1
 Mike  | Bills    | 1
 Mike  | Seahawks | 1
#+end_example

Note that the "NFL teams" example was relatively simple insofar as we needed to
validate the ~in()~ condition for each of the captures, which in our SQL code
translated to ~capture in (select teams from nfl) as valid_pref~.

In the general case there will be multiple types of conditions. This seems like
it will get complex very quickly. Notice, however, that the form of the string
returned by the ~regexp_capture()~ function is:
="capture<delim>capture<delim>capture"=, which is the same as the form required
by the [[#split][split]] function (see below). In other words, once we have validated that
the syntax of one of the values in ~`sports`.`prefs`~ is correct, we can then
call ~split~ to do the rest of the job for us; i.e., ~split("@", 3, nfl.teams,
nhl.teams, nba.teams)~ (or whatever).

* distinct

*Documentation from the VALVE README*
Usage: ~distinct(expr, [table.column, ...])~

This function validates that the contents of the target column are all
distinct. If other ~table.column~ pairs (one or more) are provided after the
~expr~, the values of the target column must also be distinct with all those
values. The ~expr~ is either a datatype or another function to perform on the
contents of the column.

*Examples:*

#+begin_example
 table    | column | condition
--------------------------------------------------------------------------
 external | ID     | distinct(concat(in(prefix.prefix), ":", numeric))
#+end_example

*Interpretation:* The values in the ~`external.ID`~ column, when transformed in
accordance with the ~concat~ function, must be distinct.

#+begin_example
 table    | column | condition
------------------------------------
 external | ID     | distinct(label)
#+end_example

*Interpretation:* The values in the ~`external.ID`~ column must be a ~label~
and they must be distinct.

#+begin_example
 table    | column | condition
--------------------------------------------------
 external | ID     | distinct(label, table.column)
#+end_example

*Interpretation:* The values in the ~`external.ID`~ column must be a ~label~,
must not be one of the values in ~table.column~ and must be distinct.

- Verifying that the target column is a particular datatype should be
  straightforward.

- Verifying that the target column corresponds to the result of calling a
  particular function on it should be straightforward (i.e., implementing
  composition (see below) may turn out to be tricky, but there is no added
  trickiness associated with validating that ~`external`.`ID`~ corresponds to
  the result of calling that function.

- Regarding the optional ~table.column~, this seems like it should be a simple
  matter of adding a ~AND NOT IN `table`.`column`~ to the ~WHERE~ clause.

* in
Usage: ~in(str-or-column, [str-or-column, ...])~

*Interpretation*

Suppose we have the following rows in the field table:

#+begin_example
table    | column            | condition                                   | note
---------------------------------------------------------------------------------
exposure | Disease Reported  | in("dengue hemorrhagic fever", "disease B") |
exposure | Exposure Material | in(external.Label)                          |
exposure | Exposure Material | in(external.Label, external.Parent)         |
#+end_example

The first row says that all values in the column:
 ~`exposure`.`Disease Reported`~ should be either "dengue hemorrhagic fever" or
 "disease B".

The second row says that all values in column: ~`exposure`.`Disease Reported`~
should match one of the values in the ~`external`.`Label`~ column.

The second row says that all values in column: ~`exposure`.`Disease Reported`~
should match either something in the ~`external`.`Label`~ column or something
in the ~`external`.`Parent`~ column.

*Implementation*

This function seems pretty straightforward to implement.

1. ~select "dengue hemorrhagic fever", "disease B";~

2. ~select Label from external;~

3. 
#+begin_src 
with labels(label) as (
  select Label from external
  union
  select Parent from external
)
select distinct label from labels;
#+end_src

* list

*Documentation from VALVE README*

~Usage: list("char", expr)~

This function splits the contents of the target column on the char (e.g, ~|~)
and then checks expr on each sub-value. The expr is either a datatype or
another function to perform. If one sub-value fails the expr check, this
function fails.

*Interpretation*

Consider:

#+begin_example
 table    | column    | condition
-------------------------------------------
 plugh    | xyzzy     | list(";", label)
#+end_example

Here we need to split the contents of ~`my_table`.`my_column`~ using ~;~, and
then verify that each token is of datatype ~label~.

To verify that a token is of datatype ~label~ we need to match it against the
regex for ~label~ (which we can retrieve from the ~datatype~ table).

The case of verifying against a function belongs to the problem of composing
functions, which is a general problem that has nothing to do with ~list~ per
se. Similarly for parents of datatypes.

*Example*

Imagine the ~plugh~ table has the following contents:

#+begin_example
 xyzzy
---------------------
 label1;label2;label3
#+end_example

From the ~datatype~ table, we see that a ~label~ is a ~trimmed_line~, which
means that it must contain no leading or trailing spaces. So, what we need to
do is break up ~label1;label2;label3~ using ~;~ and then make sure that each
token is a ~trimmed_line~ in the above sense.

#+begin_src sql
with recursive split(xyzzy, str) as (
    select
      '',
      xyzzy||';'
    from plugh
    union all
    select
      substr(str, 0, instr(str, ';')),
      substr(str, instr(str, ';')+1)
    from split where str != ''
) 
select xyzzy, regexp_matches(xyzzy, '^\w.*\w$') as valid_trimmed_line
from split
where xyzzy != '';
#+end_src

* lookup
This function is confusing and I'm not sure that I understand it. That said, it
/seems/ like it will be straightforward to implement since it appears to be
just a simple select.

* not
This seems pretty straightforward. The complications arising from composition
and/or parents are general complications that have nothing to do with ~not~ per
se.

* split

Imagine that we have the row:
#+begin_example
 table | column | condition
--------------------------------------------------------------------------
 foo   | bar    | split("," 3, goo.bar1, goo.bar2, goo.bar3)
#+end_example

And suppose the contents of the ~foo~ table are:
#+begin_example
 bar
----------------
alpha,beta,gamma
delta,epsilon,psi
alpha,beta,nu
eta,beta,lambda,omega
xi,beta
#+end_example

while the contents of the ~goo~ table are:
#+begin_example
 bar1  | bar2    | bar3
------------------------
 alpha | beta    | gamma
 delta | epsilon | psi
#+end_example

We could, for instance, generate a temp table that looks something like this:
#+begin_src sql
WITH RECURSIVE split(reference, id, bar, str) AS (
    SELECT bar, 0, '', bar||','
    FROM foo
    UNION ALL SELECT
    reference,
    id + 1,
    substr(str, 0, instr(str, ',')),
    substr(str, instr(str, ',')+1)
    FROM split
    WHERE str!=''
)
SELECT reference, id, bar
FROM split
WHERE bar != ''
ORDER BY reference;
#+end_src

The result would then be:
#+begin_example
 reference             | id | bar
-------------------------------------
 alpha,beta,gamma      | 1  | alpha
 alpha,beta,gamma      | 2  | beta
 alpha,beta,gamma      | 3  | gamma
 alpha,beta,nu         | 1  | alpha
 alpha,beta,nu         | 2  | beta
 alpha,beta,nu         | 3  | nu
 delta,epsilon,psi     | 1  | delta
 delta,epsilon,psi     | 2  | epsilon
 delta,epsilon,psi     | 3  | psi
 eta,beta,lambda,omega | 1  | eta
 eta,beta,lambda,omega | 2  | beta
 eta,beta,lambda,omega | 3  | lambda
 eta,beta,lambda,omega | 4  | omega
 xi,beta               | 1  | xi
 xi,beta               | 2  | beta
#+end_example

To display which references in ~bar~ have valid a count (which in our example
is 3):
#+begin_src sql
select
 reference,
 count(1) = 3
from result
group by reference;
#+end_src

To match the columns from ~`goo`~ with the rows from ~`result`~ we could use the
~`id`~ column from ~`result`~.

#+begin_src sql
select
 reference,
 bar,
 bar in (select bar3 from goo)
from result
where id = <id>;
#+end_src

*Here is a single query to get all of the info:*

#+begin_src sql
with split(reference, id, bar) as (
       with recursive split(reference, id, bar, str) as (
         select
           bar,
           0,
           '',
           bar||','
         from foo
         union all
         select
           reference,
           id + 1,
           substr(str, 0, instr(str, ',')),
           substr(str, instr(str, ',')+1)
         from split
         where str!=''
       )
       select reference, id, bar
       from split
       where bar != ''
     ),
     count_valid(reference, valid) as (
       select
         reference,
         count(1) = 3
       from split
       group by reference
     ),
     col1_valid(reference, valid) as (
       select
         reference,
         bar in (select bar1 from goo)
       from split
       where id = 1
     ),
     col2_valid(reference, valid) as (
       select
         reference,
         bar in (select bar2 from goo)
       from split
       where id = 2
     ),
     col3_valid(reference, valid) as (
       select
         reference,
         bar in (select bar3 from goo)
       from split
       where id = 3
     )
  select
    count_valid.reference,
    count_valid.valid as count_valid,
    col1_valid.valid as col1_valid,
    col2_valid.valid as col2_valid,
    col3_valid.valid as col3_valid
  from count_valid
    left join col1_valid on col1_valid.reference = count_valid.reference
    left join col2_valid on col2_valid.reference = count_valid.reference
    left join col3_valid on col3_valid.reference = count_valid.reference;
#+end_src

The result is:
#+begin_example
 reference             |count_valid |col1_valid | col2_valid | col3_valid
--------------------------------------------------------------------------
 alpha,beta,gamma      | 1          | 1         | 1          | 1
 alpha,beta,nu         | 1          | 1         | 1          | 0
 delta,epsilon,psi     | 1          | 1         | 1          | 1
 eta,beta,lambda,omega | 0          | 0         | 1          | 0
 xi,beta               | 0          | 0         | 1          | null
#+end_example

* sub

Consider the following example row:
#+begin_example
 table | column | condition
----------------------------------------------------------
 foo   | bar    | sub(s/pattern/replacement/[flags], expr)
#+end_example

*Interpretation:* The contents of ~`foo`.`bar`~ are transformed using the
replacement regular expression, after which the result of the transformation is
validated against ~expr~, which can be either a function or a datatype.

*Implementation*

1. We will have to create a user-defined function in Java to implement regular
   expression replacement. We have already shown that it is possible to
   implement a user-defined function to determine whether a string matches a
   given regular expression. Creating another function to implement replacement
   should be pretty straightforward since we can just use the Java libraries.

2. Assuming that we have implemented a regular expression replacement function
   as above, the rest should be pretty straightforward. We would simply have to
   do something like the following in the case, say, of ~trimmed_line~:

   Instead of:

   ~where regexp_matches(`value`, '^\w.*\w$')")~

   We would have something like:

   ~where regexp_matches(regexp_replace(value, <replacement_pattern>), '^\w.*\w$')~

* tree
Consider the following row from the ~field~ table:

#+begin_example
   table  | column | condition
----------------------------------
 external | Parent | tree(Label)
#+end_example

This says that the value of the ~Parent~ column in the table ~external~ must be
contained within the tree: ~tree(Label)~ to which is assigned the name
~external.Parent~. The children of this tree are taken from the column:
~external.Label~ and the parents of the tree are taken from the column
~external.Parent~.

That is, to generate the tree, look into the table ~`external`~, and for each
value of the column ~`Label`~ (each "child") associate the "parent" indicated
in the column ~`Parent`~ of that row. In this example this evaluates to:

#+begin_src clojure
{:external.Parent
 {:'administering substance in vivo' #{"exposure process"},
  :'organism' #{"material entity"},
  :'occurrence of infectious disease' #{"occurrence of disease"},
  :'dengue hemorrhagic fever' #{"disease"},
  :'occurrence of disease' #{"exposure process"},
  :'Chronic' #{"disease stage"},
  :'exposure to substance without evidence for disease' #{"exposure process"},
  :'occurrence of cancer' #{"occurrence of disease"},
  :'Hepacivirus C' #{"organism"},
  :'exposure process' #{"process"},
  :'disease stage' #{},
  :'material entity' #{},
  :'disease' #{},
  :'Acute/Recent onset' #{"disease stage"},
  :'Dengue virus' #{"organism"}}}
#+end_src

More generically:

#+begin_example
   table    | column | condition
----------------------------------
 my_table   | col_1  | tree(col_2)
#+end_example

In this case a tree named ~my_table.col_1~ whose children are taken from the
contents of ~my_table.col_2~ and whose associated parents are taken from
~my_table.col_1~.

As far as validation goes, when a rown like this is encountered in the ~`field`~
table, we will need to validate that all instances of ~`col_1`~ in ~`my_table`~ are
in the tree ~tree(col_2)~.

Note that, within ~my_table~, the "parent" column ~col_1~ could in principle
contain multiple parents split by a split character (e.g, ~|~).

*SQL code to generate tree(Label) for external.Parent*
(adapted from https://www.vivekkalyan.com/splitting-comma-seperated-fields-sqlite)

#+begin_src sql
WITH RECURSIVE split(`Label`, `splitParent`, `str`) AS (
    -- We need to exclude rows with empty parents otherwise the split function
    --  will choke:
    SELECT
      `Label`,
      '',
      `Parent`||','
    FROM `external`
    WHERE `Parent` != ''
    UNION ALL
    SELECT
      `Label`,
      substr(`str`, 0, instr(`str`, ',')),
      substr(`str`, instr(`str`, ',')+1)
    FROM `split`
    WHERE `str` != ''
) 
SELECT DISTINCT
  `Label`,
  `splitParent`
FROM `split`
WHERE `splitParent` != ''
UNION
-- Add back the empty parents:
SELECT
  `Label`,
  `Parent`
FROM `external`
WHERE `Parent` = '' 
ORDER BY `Label`;
#+end_src

Note that the ~tree()~ function accepts an optional parameter specifying another
tree name. E.g.,

#+begin_example
   table  | column | condition
----------------------------------
 external | Parent | tree(Label, table_name.column_name)
#+end_example

It is assumed that the tree ~table_name.column_name~ has already been
defined. Presumably the SQL will have been generated similarly to above when
that tree has been defined. In terms of validation we will just have to check
that all the values of the ~external.Parent~ column are in either:

  ~external.Parent~ (a tree name) := ~tree(Label)~

  or

  ~table_name.column_name~ (a tree name) := ~tree(whatever)~

*Questions*

- In =valve.clj= we actually generate maps corresponding to trees and store them
  in ~config~. Do we want to do something similar, i.e., create a table for
  them in Sqlite? Or do we want to generate them on the fly in a temp table
  every time?

* under
Assume that we have generated a tree in accordance with ~tree~ (see
above). Let's assume that we have populated the following table which
corresponds to ~`external.Parent`~.

*Note* that I have added an extra parent ('disease stage') to 'dengue
hemorrhagic fever' - just so that we can have a case of multiple parents to
play with.

*Note also* that we can either store this table permanently in the sqlite db or
generate it on the fly as a temp table each time. Nothing below assumes either
one of these.

#+begin_example
child                                              | parent
------------------------------------------------------------------------------
Acute/Recent onset                                 | disease stage
Chronic                                            | disease stage
Dengue virus                                       | organism
Hepacivirus C                                      | organism
administering substance in vivo                    | exposure process
dengue hemorrhagic fever                           | disease
dengue hemorrhagic fever                           | disease stage
disease                                            |
disease stage                                      |
exposure process                                   | process
exposure to substance without evidence for disease | exposure process
material entity                                    |
occurrence of cancer                               | occurrence of disease
occurrence of disease                              | exposure process
occurrence of infectious disease                   | occurrence of disease
organism                                           | material entity
#+end_example

The syntax of ~under~ is as follows:
 ~under(table.column, "top level", [direct=true])~

We will need to look for all the descendants of "top level" in the tree. In
other words what's required is a reverse search. For instance suppose we
specify ~under(table.column, 'material entity')~. The children of material
entity are:
- organism (direct)
- Dengue virus (indirect)
- Hepacivirus C (indirect)

Suppose we have:

#+begin_example
table    | column                     | condition
---------------------------------------------------------------------------------
exposure | Exposure Material Reported | under(external.Parent, "material entity")
#+end_example

Then what we need to do is to validate that the contents of the
~`Exposure Material Reported`~ column in the exposure table are all underneath
"material entity" in the tree associated with ~external.Parent~ (the one
described above).

The ~direct = true~ case:
#+begin_src sql
select child
from external_parent_tree
where parent='material entity';
#+end_src

The ~direct != true~ case:
#+begin_src sql
with recursive tree(`child`, `parent`) as (
  select `child`, `parent`
  from `external_parent_tree`
  where `parent` = 'material entity'
  union all
  select `descendant`.`child`, `descendant`.`parent`
  from `external_parent_tree` as `descendant`
  join `tree` as `ancestor` on `ancestor`.`child` = `descendant`.`parent`
)
select `child` from `tree`;
#+end_src

* SQL queries for functions that call other functions (composition)

TBD

* SQL queries for functions on datatypes that have parents

TBD
